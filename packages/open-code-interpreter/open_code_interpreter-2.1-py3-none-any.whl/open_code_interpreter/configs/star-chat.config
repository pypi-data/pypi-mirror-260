# The temperature parameter controls the randomness of the model's output. Lower values make the output more deterministic.
temperature = 0.1

# The maximum number of new tokens that the model can generate.
max_tokens = 1024

# The start separator for the generated code.
start_sep = <|assistant|>

# The end separator for the generated code.
end_sep = <|end|>

# If True, the first line of the generated text will be skipped.
skip_first_line = False

# The model used for generating the code.
HF_MODEL = HuggingFaceH4/starchat-beta
