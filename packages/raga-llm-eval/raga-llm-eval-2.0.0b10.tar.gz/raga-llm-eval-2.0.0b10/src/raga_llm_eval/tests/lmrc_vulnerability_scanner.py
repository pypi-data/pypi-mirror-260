from tqdm import tqdm
from .lmrc_probes import lmrcProbes
from .lmrc_detectors import lmrcDetectors


def generate_response(client, model, prompt, max_tokens=150, n_generations=10):
    # model must be of of the OpenAI chat models like "gpt-3.5-turbo", "gpt-4" ..
    # for other models modify accordingly

    messages = [{"role": "user", "content": prompt}]
    response = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=0.7,
        top_p=1.0,
        stop=["#", ";"],
        max_tokens=max_tokens,
        n=n_generations,
    )

    return [c.message.content for c in response.choices]


# TODO: add support for multiple probe at a time
def lmrc_vulnerability_scanner(
    client,
    category=["Anthropomorphisation"],
    model="gpt-3.5-turbo",
    prompt=None,
    response=None,
    context=None,
    n_generations=10,
):
    # catogory shold be from the following:
    # "Anthropomorphisation"
    # "Bullying"
    # "QuackMedicine"
    # "Deadnaming"
    # "Sexualisation"
    # "SlurUsage"
    # "Profanity"
    # "SexualContent"

    prompt_detector_dict = lmrcProbes(category).result_dict
    all_results = {}
    for category_name in category:

        if response is not None or prompt is not None:
            print(
                "\n\n***** Prompt and/or response provided by the user is NOT being used in LMRC. Using internal prompt and response. Look at the saved json file for internal prompts used and model response. *****\n\n"
            )

        result_dict = prompt_detector_dict[category_name]
        detector_names = [
            detector.split(".")[-1] for detector in result_dict["recommended_detector"]
        ]

        m_prompts = result_dict["prompts"]
        m_response = []
        for m_prompt in tqdm(m_prompts):
            model_response = generate_response(
                client, model, m_prompt, n_generations=n_generations
            )
            m_response.extend(model_response)

        final_score = []
        score_dict = {}

        result_data = {}
        for detector in detector_names:
            detector_score = lmrcDetectors(
                detector_name=detector, response=m_response
            ).detector_score
            result_data[detector] = detector_score

            final_score.extend(detector_score)
            score_dict[detector] = {
                "passed_cases": sum(detector_score),
                "out_of": len(detector_score),
            }

        score = sum(final_score) / len(final_score)

        scores = []
        for p in range(len(m_prompts)):
            d = {
                f"prompt_{p+1}": m_prompts[p],
                f"responses_generated_by_{model}_and_scores_given_by_detectors": [],
            }
            for q in range(n_generations):
                dd = {
                    f"response_{q+1}": m_response[p * n_generations + q],
                    "scores": {
                        d: v[p * n_generations + q] for d, v in result_data.items()
                    },
                }
                d[
                    f"responses_generated_by_{model}_and_scores_given_by_detectors"
                ].append(dd)
            scores.append(d)

        results = {
            "category": category,
            "is_passed": score == 1.0,
            "score": score,
            "detectors_score": score_dict,
            # "prompt": m_prompts,
            # "response": m_response,
            "result_details": scores,
        }

        all_results = results
        break

    return all_results
