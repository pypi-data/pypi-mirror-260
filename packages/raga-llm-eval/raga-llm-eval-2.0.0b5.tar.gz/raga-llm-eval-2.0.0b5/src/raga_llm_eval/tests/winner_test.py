"""
Test for comparing response with expected_response
"""

from .test_utils import concept_list_str, openai_chat_request


def winner_test(
    client,
    response,
    expected_response,
    concept_set,
    model="gpt-3.5-turbo",
    temperature: float = 0,
    max_tokens: int = 512,
):
    """
    Compares response and expected_response and returns 1 if response is better than expected_response, otherwise returns 0.

    Args:
        response (str): response generated by your model.
        Pass below instruction to your LLM and ask it to generate output. Refer below example.
        instruction: "# Instruction\n\nGiven several concepts (i.e., nouns or verbs), write a short and simple sentence that contains *all* the required words.\nThe sentence should describe a common scene in daily life, and the concepts should be used in a natural way.\n\n# Examples\n\n## Example 1\n- Concepts: \"dog(noun), frisbee(noun), catch(verb), throw(verb)\"\n- Sentence: The dog catches the frisbee when the boy throws it into the air.\n\n## Example 2\n- Concepts: \"apple(noun), place(verb), tree(noun), pick(verb)\"\n- Sentence: A girl picks some apples from a tree and places them into her basket.\n\n# Your Task \n\n- Concepts: \"catch(verb), dog(noun), frisbee(noun), throw(verb)\"\n- Sentence: ",
        example_response: [
        "The dog catches the frisbee when someone throws it."
        ]

        expected_response (str): It can be human_annotation or output from some other model.
        concept_set (list): Refer below form
            concept_set: [
            "catch_V",
            "dog_N",
            "frisbee_N",
            "throw_V"
            ]
        model (str, optional): The name of the language model to be used for task of evaluating your model. Defaults to "gpt-3.5-turbo".
        temperature (float,optional): This parameter allows you to adjust the randomness of the response generated by the specified model.
        max_tokens  (int,optional): This parameter allows you to specify the maximum length of the generated response.

    NOTE: Concept_set should always conatin words in their root form.

    Returns:
        dict: A dictionary containing the evaluation results.
    """

    cs_str = concept_list_str(concept_set)
    prompt = f"""Data : Given several concepts (i.e., nouns or verbs), we ask models to write a short and simple sentence that contains *all* the required words. The sentence should describe a common scene in daily life, and the concepts should be used in a natural way.
                Concepts: {cs_str} , Model A: {response}, Model B: {expected_response}. Your task is to choose a better sentence from the two candidates. Decide which model's sentence is better in terms of the naturalness and commonness of the scenes they describe.
                Rules:
                - A better sentence should describe a common scene in daily life, and all concepts should be used in a natural way.
                - You should prefer sentences that use all given concepts with correct part-of-speech tags.
                - You should prefer sentences that use all given concepts with correct part-of-speech tags.
                - A simpler and shorter sentence is preferred if it describes the same scene as the other sentence.
                - If you think both sentences are equally good or bad, please choose *TIE*.
                - If you think both sentences are equally good or bad, please choose *TIE*.
                Now, please output your choice ("A" or "B" or "tie"). Your choice: """

    openai_args = {
        "client": client,
        "prompt": prompt,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "model": model,
        "stop": [],
    }

    res = openai_chat_request(**openai_args)

    res = res[0]
    if "a" in res.lower():
        output = 1
    else:
        output = 0

    result = {
        "response": response,
        "expected_response": expected_response,
        "concept_set": concept_set,
        "score": output,
        "evaluated_with": {"model": model},
    }

    return result
