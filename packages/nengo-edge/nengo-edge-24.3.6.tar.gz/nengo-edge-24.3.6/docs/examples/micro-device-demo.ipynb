{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f88ba99",
   "metadata": {},
   "source": [
    "# Using the NengoEdge Micro Runner\n",
    "\n",
    "In this example we will walk through loading and running a model exported from\n",
    "NengoEdge\n",
    "that's been uniquely configured to run on micro devices supporting TFLite Micro\n",
    "(we support the STM32F746 Discovery Board (Disco) and nRF52840 Dev Board\n",
    "(Nordic)). The goal\n",
    "of this demo is to provide a template for you to make your own custom\n",
    "applications using\n",
    "the NengoEdge runner."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bea010a9",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, install NengoEdge tools using\n",
    "[these instructions](https://www.nengo.ai/nengo-edge/developers.html).\n",
    "Feel free to skip the Tensorflow step since we won't need it for this\n",
    "runner.\n",
    "\n",
    "For the micro device example, it's assumed that you have completed the\n",
    "installation steps for either your Disco or Nordic board,\n",
    "\n",
    "- [Nordic guide\n",
    "](https://www.nordicsemi.com/Products/Development-software/nrf-connect-sdk)\n",
    "- [Disco guide\n",
    "](https://wiki.st.com/stm32mcu/wiki/Microcontroller)\n",
    "\n",
    "Take note of the **serial** and **drive** paths that are associated with your\n",
    "micro device as these are **required** for the Python runner. For example,\n",
    "the STM Discovery Board should generate serial and drive paths on your\n",
    "system named something like `/dev/ttyACM0`\n",
    "and `/media/<username>/DIS_F746NG` respectively (exact names will depend on\n",
    "your system)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38218e2a",
   "metadata": {},
   "source": [
    "## Train a model in NengoEdge\n",
    "\n",
    "The first step is to train a model in NengoEdge for your desired hardware. See\n",
    "[this blog post\n",
    "](https://appliedbrainresearch.com/blog/fast-keyword-detection-with-lmus-on-gpu)\n",
    "for a detailed walkthrough on how to train such a model.\n",
    "\n",
    "## Export the trained model\n",
    "\n",
    "When exporting the model from NengoEdge you must choose the \"BINARY\" option to get a\n",
    "model targeted to run on microcontroller devices that use TFLiteMicro. The downloaded\n",
    "artifacts can be unpacked to a directory of your choice, and for the purpose of this\n",
    "demo we'll assume the contents have been unpacked to a directory called `micro_demo/`.\n",
    "\n",
    "Inside this directory you'll find two files (note: the binary file extension may change\n",
    "depending on the specific device):\n",
    "\n",
    "- `nengoedge_project.bin`\n",
    "- `parameters.json`\n",
    "\n",
    "We'll create a `DiscoRunner` that utilizes these artifacts.\n",
    "\n",
    "Note that if you are running this code locally, you will need to uncomment the\n",
    "`os.environ` lines and update `<DISCO_SERIAL_PATH>`/`<DISCO_DRIVE_PATH>` to point to\n",
    "the serial/drive path (see the Installation steps above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ba6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from nengo_edge import DiscoRunner\n",
    "\n",
    "# os.environ[\"DISCO_SERIAL_PATH\"] = <DISCO_SERIAL_PATH>\n",
    "# os.environ[\"DISCO_DRIVE_PATH\"] = <DISCO_DRIVE_PATH>\n",
    "runner = DiscoRunner(\n",
    "    directory=\"micro_demo\",\n",
    "    serial_path=os.environ[\"DISCO_SERIAL_PATH\"],\n",
    "    device_path=os.environ[\"DISCO_DRIVE_PATH\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b77fde9",
   "metadata": {},
   "source": [
    "You will likely have particular audio inputs you are interested in identifying with the\n",
    "edge key word spotting model, but we'll showcase the general run steps assuming a random\n",
    "signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a42836",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_inputs = np.random.uniform(\n",
    "    -1, 1, (1, runner.preprocessing[\"sample_rate\"])\n",
    ").astype(\"float32\")\n",
    "\n",
    "# Keyword labels for model outputs\n",
    "labels = [\n",
    "    \"<silence>\",\n",
    "    \"<unknown>\",\n",
    "    \"yes\",\n",
    "    \"no\",\n",
    "    \"up\",\n",
    "    \"down\",\n",
    "    \"left\",\n",
    "    \"right\",\n",
    "    \"on\",\n",
    "    \"off\",\n",
    "    \"stop\",\n",
    "    \"go\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f131ede6",
   "metadata": {},
   "source": [
    "And finally we can run the model using a microcontroller device,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a21676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the runner's context opens the serial communication\n",
    "# to the board set by serial_path\n",
    "with runner:\n",
    "    outputs = runner.run(audio_inputs)\n",
    "    pred_label = np.argmax(outputs)\n",
    "    print(f\"Predicted keyword: {labels[pred_label]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53be66c2",
   "metadata": {},
   "source": [
    "Since we used a random audio sample here and the model was trained on real audio\n",
    "samples, it's likely this particular classification will\n",
    "result in a random label. You'll notice that in this example we only ran the model\n",
    "on a single batch of inputs but the runner also supports batched inputs.\n",
    "\n",
    "That's it! You're now set to take this runner into your own applications."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
