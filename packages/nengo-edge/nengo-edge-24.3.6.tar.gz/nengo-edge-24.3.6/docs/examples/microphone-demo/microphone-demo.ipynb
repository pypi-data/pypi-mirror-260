{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f88ba99",
   "metadata": {},
   "source": [
    "# Deploying a model with live microphone input\n",
    "\n",
    "In this example we will walk through loading a model exported from NengoEdge,\n",
    "and deploying that model in a simple application that detects\n",
    "keywords from live microphone input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36a7fbb",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, install NengoEdge tools\n",
    "using [these instructions](https://www.nengo.ai/nengo-edge/developers.html).\n",
    "\n",
    "For this example, you will also need to install:\n",
    "\n",
    "- [sounddevice](https://python-sounddevice.readthedocs.io/en/latest/)\n",
    "- [Jupyter Notebook or JupyterLab](https://jupyter.org/)\n",
    "\n",
    "### Conda/Mamba\n",
    "\n",
    "```bash\n",
    "conda activate nengo-edge\n",
    "conda install python-sounddevice notebook\n",
    "```\n",
    "\n",
    "### pip\n",
    "\n",
    "On Ubuntu/Debian, first:\n",
    "\n",
    "```bash\n",
    "sudo apt install libportaudio2\n",
    "```\n",
    "\n",
    "On all platforms, including Ubuntu/Debian:\n",
    "\n",
    "```bash\n",
    "pip install sounddevice notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dbdf19",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "# Ensure dependencies are installed\n",
    "try:\n",
    "    import sounddevice\n",
    "\n",
    "    assert sounddevice\n",
    "except ImportError:\n",
    "    print(\"sounddevice is not installed. See above for instructions.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38218e2a",
   "metadata": {},
   "source": [
    "## Train a model in NengoEdge\n",
    "\n",
    "The first step is to train a model in NengoEdge. See [this blog\n",
    "post](https://appliedbrainresearch.com/blog/fast-keyword-detection-with-lmus-on-gpu)\n",
    "for a detailed walkthrough on how to train such a model.\n",
    "\n",
    "You can use whatever dataset you like, but make sure to match the parameters below\n",
    "to your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f610235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword labels for model outputs\n",
    "labels = [\n",
    "    \"<silence>\",\n",
    "    \"<unknown>\",\n",
    "    \"yes\",\n",
    "    \"no\",\n",
    "    \"up\",\n",
    "    \"down\",\n",
    "    \"left\",\n",
    "    \"right\",\n",
    "    \"on\",\n",
    "    \"off\",\n",
    "    \"stop\",\n",
    "    \"go\",\n",
    "]\n",
    "\n",
    "# Sample rate of audio files in the dataset\n",
    "sample_rate = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb2499",
   "metadata": {},
   "source": [
    "After training your model in NengoEdge, download the \"TFLite\" artifact\n",
    "from the Deployment page.\n",
    "\n",
    "Make sure to set the string passed to `TFLiteRunner` to\n",
    "the directory containing the extracted deployment files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ba6a2",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd  # pylint: disable=ungrouped-imports\n",
    "\n",
    "from nengo_edge import TFLiteRunner\n",
    "\n",
    "runner = TFLiteRunner(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b77fde9",
   "metadata": {},
   "source": [
    "Next we need to select the microphone input device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a42836",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "print(f\"Available devices:\\n{sd.query_devices()}\")\n",
    "mic_device_ix = int(input(\"Index of input device to listen to: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f131ede6",
   "metadata": {},
   "source": [
    "And finally we can run the model using that device. As you speak into your microphone,\n",
    "it will print out the keywords detected by the model.\n",
    "\n",
    "Note that the particular input method below is not a requirement. The important part is\n",
    "that we call `runner.run` in a loop, feeding it the new audio samples each time. This\n",
    "can be adapted to whatever approach makes the most sense for your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a21676",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "inference_rate = 0.2  # How often to do a classification, in seconds\n",
    "block_size = int(sample_rate * inference_rate)\n",
    "\n",
    "\n",
    "def callback(data, frames, time, status):\n",
    "    # Call model periodically as new data comes in\n",
    "    outputs = runner.run(data.T)\n",
    "    label = labels[np.argmax(outputs)]\n",
    "    if label != \"<silence>\":\n",
    "        print(label)\n",
    "\n",
    "\n",
    "try:\n",
    "    with sd.InputStream(\n",
    "        device=mic_device_ix,\n",
    "        samplerate=sample_rate,\n",
    "        blocksize=block_size,\n",
    "        latency=\"low\",\n",
    "        channels=1,\n",
    "        dtype=np.float32,\n",
    "        callback=callback,\n",
    "    ):\n",
    "        print(\"Press Enter to quit\")\n",
    "        input()\n",
    "    print(\"Exiting\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
