[LOCALE]
plugin.name = Chat with files (Llama-index, inline)
plugin.description = Integrates Llama-index (Chat with files) storage in any chat and provides additional knowledge into context (from files and from context history in database)

prompt.label = Prompt
prompt.description = Prompt used for instruct how to use additional data provided from Llama-index
prompt.tooltip = Prompt

ask_llama_first.label = Ask Llama-index first
ask_llama_first.description = When enabled, then Llama-index will be asked first, and response will be used as additional knowledge in prompt. When disabled, then Llama-index will be asked only when needed.
ask_llama_first.tooltip = Ask Llama-index first

model_query.label = Model
model_query.description = Model used for querying Llama-index, default: gpt-3.5-turbo
model_query.tooltip = Model

idx.label = Indexes to use
idx.description = ID's of indexes to use, default: base, separate by comma if you want to use more than one index at once
idx.tooltip = Indexes to use
