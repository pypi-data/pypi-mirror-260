Metadata-Version: 2.1
Name: nlbq
Version: 0.1.6
Summary: Natural language to BigQuery
Author: Tom Dyson, Dan Braghis
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Classifier: License :: OSI Approved :: MIT License
Requires-Dist: openai
Requires-Dist: fastapi
Requires-Dist: pydantic-settings
Requires-Dist: uvicorn[standard]
Requires-Dist: tabulate
Requires-Dist: typer
Requires-Dist: python-dotenv
Requires-Dist: nldb
Requires-Dist: google-cloud-bigquery
Requires-Dist: pre-commit >=3.3.2 ; extra == "lint"
Project-URL: Home, https://github.com/torchbox/nlbq
Provides-Extra: lint

# nlbq
Natural language interface to BigQuery

## Google credentials

The Python BigQuery library expects the environment variable `GOOGLE_APPLICATION_CREDENTIALS`, which should point to a JSON file containing the credentials of a Google service account. You can create a service account and download its credentials from the [Google Cloud Console](https://console.cloud.google.com/iam-admin/serviceaccounts). Then set the environment variable:

```bash
export GOOGLE_APPLICATION_CREDENTIALS=/path/to/your/google-service-account.json
```

## Creating a demo environment

```bash
mkdir demo # Git will ignore this directory
cd demo
python3 -m venv venv
source venv/bin/activate
pip install -e ../ # Install the local package in editable mode
nlbq init  # generates prompt.txt, Dockerfile and index.html
# make changes then
pip uninstall nlbq --yes; pip install -e ../
```

You can initialise with prepopulated BigQuery dataset table schema information with

```bash
nlbq init --table dataset.table_id
```

## Usage

```bash
nlbq --help
```

