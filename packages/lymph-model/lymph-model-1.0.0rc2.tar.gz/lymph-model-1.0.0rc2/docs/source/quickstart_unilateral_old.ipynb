{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "A lot of people get diagnosed with squamous cell carcinoma in the head & neck region ([HNSCC](https://en.wikipedia.org/wiki/Head_and_neck_cancer)), which frequently metastasizes via the lymphatic system. We set out to develop a methodology to predict the risk of a new patient having metastases in so-called lymph node levels (LNLs), based on their personal diagnose (e.g. findings from a CT scan) and information of previously diagnosed and treated patients. And that's exactly what this code enables you to do as well.\n",
    "\n",
    "As mentioned, this package is meant to be a relatively simple-to-use frontend. The math is done under the hood and one does not need to worry about it a lot. But let's have a quick look at what we're doing here.\n",
    "\n",
    "We will assume that you have already read the section on how to install the module and followed its instructions.\n",
    "\n",
    "## Importing\n",
    "\n",
    "First, let's import the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lymph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph\n",
    "\n",
    "The model is based on the assumption that one can represent the lymphatic system as a directed graph. The arcs in that graph represent the direction of the lymphatic flow and therefore also the direction of metastatic spread. Hence, the first thing to do is to define a graph that represents the drainage pathways of the lymphatic system aptly.\n",
    "\n",
    "Here, this is done via a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {\n",
    "    ('tumor', 'primary')  : ['I', 'II', 'III', 'IV'], \n",
    "    ('lnl'  , 'I')  :       ['II'], \n",
    "    ('lnl'  , 'II') :       ['III'], \n",
    "    ('lnl'  , 'III'):       ['IV'], \n",
    "    ('lnl'  , 'IV') :       []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every key in this dictionary is a tuple of the form `({type}, {name})` and represents either a tumor - in which case the `{type}` must be `'tumor'` - or a lymph node level (`{type}` must be `'lnl'`). The value of each of those nodes is then a list of names for nodes it connects to. So, for example the primary tumor `('tumor', 'primary')` in the `graph` above has directed arcs to `a` and `b`, while the LNL `c` does not have any outgoing connections.\n",
    "\n",
    "We can simply create an instance of `System` using only this graph and let it report itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unilateral_model = lymph.Unilateral(graph=graph)\n",
    "print(unilateral_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentages between two nodes represents the probability rate that metastatic spread occurs along it. In the case of the tumor spreading to LNL `a` we call this probability *base probability rate* $\\tilde{b}_a$. For the spread between lymph node levels, we call it *transition probability rate*, e.g. $\\tilde{t}_{ab}$. The difference to the base probability rate is that it only plays a role if the parent LNL is already ivolved with metastases, while the tumor always spreads, of course.\n",
    "\n",
    "We can change these spread probability rates by setting the attribute `spread_probs` of the `System`. It can be set with an array of these spread sprobability rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unilateral_model.spread_probs = [0.05, 0.3, 0.2, 0.15, 0.1, 0.25, 0.2]\n",
    "print(unilateral_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reversely, we can also read them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_probabilities = unilateral_model.spread_probs\n",
    "print(spread_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic Modalities\n",
    "\n",
    "To ultimately compute the likelihoods of observations, we need to fix the sensitivities and specificities of the obtained diagnoses. And since we might have multiple diagnostic modalities available, we need to tell the system which of them comes with which specificity and sensitivity. We do this by creating a dictionary of specificity/sensitivity pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_and_pet_spsn = {\"MRI\": [0.63, 0.81], \n",
    "                    \"PET\": [0.86, 0.79]}\n",
    "#                           ^     ^\n",
    "#                  specificty     sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass this to the system by setting the `modalities` attribute, which expects a dictionary containing the diagnostic modalities and as a key to it the numbers for specificity & sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unilateral_model.modalities = mri_and_pet_spsn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data / Observations\n",
    "\n",
    "To compute the likelihood of a set of probability (rates) given a patient cohort we need such a patient cohort, of course. We can provide it to the system in the form of a `pandas` `DataFrame`. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lyscripts.data.clean import lyprox_to_lymph\n",
    "\n",
    "dataset_url = \"https://raw.githubusercontent.com/rmnldwg/lydata/main/2021-usz-oropharynx/data.csv\"\n",
    "example_cols = [\n",
    "    (\"info\", \"t_stage\"),\n",
    "    (\"PET\", \"I\"),\n",
    "    (\"PET\", \"II\"),\n",
    "    (\"PET\", \"III\"),\n",
    "    (\"PET\", \"IV\"),\n",
    "    (\"MRI\", \"I\"),\n",
    "    (\"MRI\", \"II\"),\n",
    "    (\"MRI\", \"III\"),\n",
    "    (\"MRI\", \"IV\"),\n",
    "]\n",
    "\n",
    "dataset = lyprox_to_lymph(pd.read_csv(dataset_url, header=[0,1,2]))\n",
    "dataset[example_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this data has two header-rows, defining not only the individual column's content, but also to which over-arching category they belong. The \"Info\" category plays a special role here along with its sub-category \"T-stage\". It will later tell the system which time prior to use according to a dictionary of these distributions.\n",
    "\n",
    "The \"pathology\" section denotes that this dataset contains observations from a pathologic diagnostic modality (neck dissections in this case). How this is termed is irrelevant, as we will be telling the system what to look for. Import is, however, that - if we had multiple diagnostic modalities - they all contain a column for each lymph node level in the system we have set up. Obvioulsy, this dataset here does not match the system set up earlier, so let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unilateral_model.modalities = {\"PET\": [0.86, 0.79]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To feed the dataset into the system, we assign the dataset to the attribute `patient_data`. What the system then does here is creating a diagnose matrix for every T-stage in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unilateral_model.patient_data = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we get a warning that we have no distributions defined for marginalizing over diagnose times. This is the next step.\n",
    "\n",
    "## Distribution over diagnose times\n",
    "\n",
    "The last ingredient to set up (at least when using the hidden Markov model) would now be the time prior. Since this dataset contains only early T-stage patients the exact shape does not matter too much, as long as it is \"reasonable\". If we also had late T-stage patients in the cohort, we would need to think about how the two time priors relate to each other.\n",
    "\n",
    "For now we are going to use binomial distributions for this. Their shape makes intuitive sense: Since the time prior $p_T(t)$ is a distribution over the probability of diagnosing a patient after $t$ time steps, given his T-stage $T$ we would expect that a very early detection of the cancer is similarly unlikely as a very late one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_t = 10\n",
    "time_steps = np.arange(max_t+1)\n",
    "p = 0.4\n",
    "\n",
    "early_prior = sp.stats.binom.pmf(time_steps, max_t, p)\n",
    "\n",
    "plt.plot(time_steps, early_prior, \"o-\");\n",
    "plt.xlabel(\"time step $t$\");\n",
    "plt.ylabel(\"probability $p$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unilateral_model.diag_time_dists[\"early\"] = early_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import factorial\n",
    "\n",
    "def binom_pmf(k: np.ndarray, n: int, p: float):\n",
    "    \"\"\"Binomial PMF\"\"\"\n",
    "    if p > 1. or p < 0.:\n",
    "        raise ValueError(\"Binomial prob must be btw. 0 and 1\")\n",
    "    q = (1. - p)\n",
    "    binom_coeff = factorial(n) / (factorial(k) * factorial(n - k))\n",
    "    return binom_coeff * p**k * q**(n - k)\n",
    "\n",
    "def parametric_binom_pmf(n: int):\n",
    "    \"\"\"Return a parametric binomial PMF\"\"\"\n",
    "    def inner(t, p):\n",
    "        \"\"\"Parametric binomial PMF\"\"\"\n",
    "        return binom_pmf(t, n, p)\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unilateral_model.diag_time_dists[\"late\"] = parametric_binom_pmf(max_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood\n",
    "\n",
    "With everything set up like this, we can compute the likelihood of seeing the above dataset given a set of base and transition probability (rates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probabilities = np.array([0.02, 0.24, 0.03, 0.2, 0.23, 0.18, 0.18, 0.5])\n",
    "\n",
    "llh = unilateral_model.likelihood(given_params=test_probabilities, log=True)\n",
    "\n",
    "print(f\"log-likelihood is {llh:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here it is up to the user what to do with this quantity. Most *likely* though, one would want to perform MCMC sampling with this.\n",
    "\n",
    "## Summary\n",
    "\n",
    "To set up a model for lymphatic metastatic spread, you need to do the following things:\n",
    "\n",
    "1. Define a graph that connects the lymph node levels via a dictionary\n",
    "2. Provide the specificity & sensitivity of the diagnostic modalities to the `modalities` attribute\n",
    "3. Assign your correctly formatted pandas `DataFrame` to the attribute `patient_data` of the model\n",
    "4. For each T-stage in the data, define a distribution over possible diagnose times\n",
    "\n",
    "Then, you can use the `log_likelihood` method to compute the log-likelihood of the stored data given an array of parameters - the spread probabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "1b6eded5f386e55fd051b894079e4370359bf13f51a44183870a4399bfd4d593"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
