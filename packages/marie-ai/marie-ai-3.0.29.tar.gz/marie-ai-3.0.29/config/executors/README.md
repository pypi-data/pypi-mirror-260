---
language: en
tags:
- layoutlmv3-large
- rms/layoutlmv3-large-corr-ner
license: apache-2.0
datasets:
- corr-indexer
- custom
---


# Model information
Loading best model from /mnt/data/models/layoutlmv3-large-fullyannotated-dropout/checkpoint-23000 (score: 0.8805799021182203).

{'train_runtime': 52559.7425, 'train_samples_per_second': 9.513, 'train_steps_per_second': 0.476, 'train_loss': 0.012078752517551184, 'epoch': 2.92}
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25000/25000 [14:35:59<00:00,  2.10s/it]
Saving model checkpoint to /mnt/data/models/layoutlmv3-large-fullyannotated-dropout
Configuration saved in /mnt/data/models/layoutlmv3-large-fullyannotated-dropout/config.json
Model weights saved in /mnt/data/models/layoutlmv3-large-fullyannotated-dropout/pytorch_model.bin
Feature extractor saved in /mnt/data/models/layoutlmv3-large-fullyannotated-dropout/preprocessor_config.json
tokenizer config file saved in /mnt/data/models/layoutlmv3-large-fullyannotated-dropout/tokenizer_config.json
Special tokens file saved in /mnt/data/models/layoutlmv3-large-fullyannotated-dropout/special_tokens_map.json
***** train metrics *****
  epoch                    =        2.92
  train_loss               =      0.0121
  train_runtime            = 14:35:59.74
  train_samples            =      171200
  train_samples_per_second =       9.513
  train_steps_per_second   =       0.476
***** Running Evaluation *****
  Num examples = 19750



f1': 0.5, 'eval_BILLED_AMT_ANSWER_number': 2500, 'eval_BIRTHDATE_precision': 0.9701399300349826, 'eval_BIRTHDATE_recall': 0.970625, 'eval_BIRTHDATE_f1': 0.9703824043989003, 'eval_BIRTHDATE_number': 8000, 'eval_BIRTHDATE_ANSWER_precision': 0.9986864573755418, 'eval_BIRTHDATE_ANSWER_recall': 0.950375, 'eval_BIRTHDATE_ANSWER_f1': 0.973931979760456, 'eval_BIRTHDATE_ANSWER_number': 8000, 'eval_CLAIM_NUMBER_precision': 0.8865478119935171, 'eval_CLAIM_NUMBER_recall': 0.9945454545454545, 'eval_CLAIM_NUMBER_f1': 0.937446443873179, 'eval_CLAIM_NUMBER_number': 2750, 'eval_CLAIM_NUMBER_ANSWER_precision': 0.9104876419505677, 'eval_CLAIM_NUMBER_ANSWER_recall': 0.9077589077589078, 'eval_CLAIM_NUMBER_ANSWER_f1': 0.9091212272803068, 'eval_CLAIM_NUMBER_ANSWER_number': 3003, 'eval_COMPANY_precision': 0.8340683572216097, 'eval_COMPANY_recall': 0.8734845360824742, 'eval_COMPANY_f1': 0.8533215163356564, 'eval_COMPANY_number': 24250, 'eval_DATE_precision': 0.8617563250151109, 'eval_DATE_recall': 0.8769000966523153, 'eval_DATE_f1': 0.869262259385071, 'eval_DATE_number': 11381, 'eval_DOCUMENT_CONTROL_precision': 0.7231871471993052, 'eval_DOCUMENT_CONTROL_recall': 0.7285120653204054, 'eval_DOCUMENT_CONTROL_f1': 0.7258398402033774, 'eval_DOCUMENT_CONTROL_number': 13717, 'eval_DOS_precision': 0.9169702914798207, 'eval_DOS_recall': 0.9183859649122808, 'eval_DOS_f1': 0.9176775822172359, 'eval_DOS_number': 14250, 'eval_DOS_ANSWER_precision': 0.9473380464579426, 'eval_DOS_ANSWER_recall': 0.9056551724137931, 'eval_DOS_ANSWER_f1': 0.9260277836541851, 'eval_DOS_ANSWER_number': 14500, 'eval_FOOTER_precision': 0.7917976939203354, 'eval_FOOTER_recall': 0.8009277667329358, 'eval_FOOTER_f1': 0.7963365619028793, 'eval_FOOTER_number': 7545, 'eval_GREETING_precision': 0.9259639048400328, 'eval_GREETING_recall': 0.9381233377659575, 'eval_GREETING_f1': 0.9320039633391132, 'eval_GREETING_number': 24064, 'eval_HEADER_precision': 0.7307440302853815, 'eval_HEADER_recall': 0.8525140139289961, 'eval_HEADER_f1': 0.7869462955703646, 'eval_HEADER_number': 23548, 'eval_IDENTIFIER_precision': 0.738625783626094, 'eval_IDENTIFIER_recall': 0.5530510758934796, 'eval_IDENTIFIER_f1': 0.6325077070266822, 'eval_IDENTIFIER_number': 21517, 'eval_LETTER_DATE_precision': 0.9436401240951396, 'eval_LETTER_DATE_recall': 0.9733333333333334, 'eval_LETTER_DATE_f1': 0.958256760304542, 'eval_LETTER_DATE_number': 18750, 'eval_LIST_precision': 0.6759067590675907, 'eval_LIST_recall': 0.7445226529195995, 'eval_LIST_f1': 0.7085574110765168, 'eval_LIST_number': 10087, 'eval_MEMBER_NAME_precision': 0.9825575792618291, 'eval_MEMBER_NAME_recall': 0.9942467089224768, 'eval_MEMBER_NAME_f1': 0.9883675843350136, 'eval_MEMBER_NAME_number': 10255, 'eval_MEMBER_NAME_ANSWER_precision': 0.9915933906657648, 'eval_MEMBER_NAME_ANSWER_recall': 0.9984432769021211, 'eval_MEMBER_NAME_ANSWER_f1': 0.9950065448198964, 'eval_MEMBER_NAME_ANSWER_number': 10278, 'eval_MEMBER_NUMBER_precision': 0.9737730459620878, 'eval_MEMBER_NUMBER_recall': 0.9836065573770492, 'eval_MEMBER_NUMBER_f1': 0.9786651008025055, 'eval_MEMBER_NUMBER_number': 15250, 'eval_MEMBER_NUMBER_ANSWER_precision': 0.9496843313564186, 'eval_MEMBER_NUMBER_ANSWER_recall': 0.9755011135857461, 'eval_MEMBER_NUMBER_ANSWER_f1': 0.9624196206417424, 'eval_MEMBER_NUMBER_ANSWER_number': 15266, 'eval_MONEY_precision': 0.28104956268221576, 'eval_MONEY_recall': 0.482, 'eval_MONEY_f1': 0.3550644567219152, 'eval_MONEY_number': 1000, 'eval_PAID_AMT_precision': 0.0, 'eval_PAID_AMT_recall': 0.0, 'eval_PAID_AMT_f1': 0.0, 'eval_PAID_AMT_number': 0, 'eval_PAID_AMT_ANSWER_precision': 0.0, 'eval_PAID_AMT_ANSWER_recall': 0.0, 'eval_PAID_AMT_ANSWER_f1': 0.0, 'eval_PAID_AMT_ANSWER_number': 0, 'eval_PAN_precision': 0.8450395427139613, 'eval_PAN_recall': 0.8464313725490196, 'eval_PAN_f1': 0.8457348849966694, 'eval_PAN_number': 12750, 'eval_PAN_ANSWER_precision': 0.8581513708750615, 'eval_PAN_ANSWER_recall': 0.7882672296787815, 'eval_PAN_ANSWER_f1': 0.8217261436880994, 'eval_PAN_ANSWER_number': 13262, 'eval_PARAGRAPH_precision': 0.7731587079685086, 'eval_PARAGRAPH_recall': 0.8525167765788528, 'eval_PARAGRAPH_f1': 0.8109007926446107, 'eval_PARAGRAPH_number': 86281, 'eval_PATIENT_NAME_precision': 0.9722840192806822, 'eval_PATIENT_NAME_recall': 0.9989523809523809, 'eval_PATIENT_NAME_f1': 0.9854378053363397, 'eval_PATIENT_NAME_number': 10500, 'eval_PATIENT_NAME_ANSWER_precision': 0.9758498131778001, 'eval_PATIENT_NAME_ANSWER_recall': 0.9291106290672451, 'eval_PATIENT_NAME_ANSWER_f1': 0.9519068361632146, 'eval_PATIENT_NAME_ANSWER_number': 11525, 'eval_PHONE_precision': 0.8356095093576126, 'eval_PHONE_recall': 0.944, 'eval_PHONE_f1': 0.8865038905285753, 'eval_PHONE_number': 3500, 'eval_PROC_CODE_precision': 0.8546879710581851, 'eval_PROC_CODE_recall': 0.8723076923076923, 'eval_PROC_CODE_f1': 0.8634079488350845, 'eval_PROC_CODE_number': 3250, 'eval_PROC_CODE_ANSWER_precision': 0.277727023570254, 'eval_PROC_CODE_ANSWER_recall': 0.8106666666666666, 'eval_PROC_CODE_ANSWER_f1': 0.41371801850843765, 'eval_PROC_CODE_ANSWER_number': 3750, 'eval_PROVIDER_precision': 0.9808301886792453, 'eval_PROVIDER_recall': 0.9996923076923077, 'eval_PROVIDER_f1': 0.9901714285714286, 'eval_PROVIDER_number': 13000, 'eval_PROVIDER_ANSWER_precision': 0.9480129814463291, 'eval_PROVIDER_ANSWER_recall': 0.9978087135859758, 'eval_PROVIDER_ANSWER_f1': 0.972273683549471, 'eval_PROVIDER_ANSWER_number': 15516, 'eval_QUESTION_precision': 0.8609450569257112, 'eval_QUESTION_recall': 0.8429659695873408, 'eval_QUESTION_f1': 0.851860658661277, 'eval_QUESTION_number': 67998, 'eval_URL_precision': 1.0, 'eval_URL_recall': 1.0, 'eval_URL_f1': 1.0, 'eval_URL_number': 9253, 'eval_overall_precision': 0.8563541608697218, 'eval_overall_recall': 0.8763555049329157, 'eval_overall_f1': 0.8662393912401363, 'eval_overall_accuracy': 0.917465295648105, 'eval_runtime': 883.6377, 'eval_samples_per_second': 22.351, 'eval_steps_per_second': 1.863, 'epoch': 0.23}
